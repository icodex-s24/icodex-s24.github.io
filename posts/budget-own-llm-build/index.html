<!doctype html><html lang="en" data-mode="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7" /><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e" /><meta name="apple-mobile-web-app-capable" content="yes" /><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" /><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" /><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Estimated cost associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities." /><meta name="author" content="iaiguru" /><meta property="og:locale" content="en" /><meta name="description" content="Building a large language model (LLM) with a focus on using lower-cost GPUs, such as the NVIDIA RTX 4090, involves significant computational resources. Below is a detailed breakdown of the estimated costs associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities." /><meta property="og:description" content="Building a large language model (LLM) with a focus on using lower-cost GPUs, such as the NVIDIA RTX 4090, involves significant computational resources. Below is a detailed breakdown of the estimated costs associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities." /><link rel="canonical" href="/posts/budget-own-llm-build/" /><meta property="og:url" content="/posts/budget-own-llm-build/" /><meta property="og:site_name" content="iCodeX’s blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-09-07T04:00:24-04:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Estimated cost associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities." /><meta name="twitter:site" content="@icodex-s24" /><meta name="twitter:creator" content="@iaiguru" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"iaiguru"},"dateModified":"2024-09-07T04:00:24-04:00","datePublished":"2024-09-07T04:00:24-04:00","description":"Building a large language model (LLM) with a focus on using lower-cost GPUs, such as the NVIDIA RTX 4090, involves significant computational resources. Below is a detailed breakdown of the estimated costs associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities.","headline":"Estimated cost associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities.","mainEntityOfPage":{"@type":"WebPage","@id":"/posts/budget-own-llm-build/"},"url":"/posts/budget-own-llm-build/"}</script><title>Estimated cost associated with memory and GPU devices while considering the RTX 4090's pricing and capabilities. | iCodeX's blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="iCodeX's blog"><meta name="application-name" content="iCodeX's blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css" /><link rel="stylesheet" href="/assets/lib/fonts/main.css" /><link rel="stylesheet" href="/assets/lib/fontawesome-free/css/all.min.css" /><link rel="stylesheet" href="/assets/lib/tocbot/tocbot.min.css" /><link rel="stylesheet" href="/assets/lib/loading-attribute-polyfill/loading-attribute-polyfill.min.css" /><link rel="stylesheet" href="/assets/lib/glightbox/glightbox.min.css" /><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/logo.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a><h1 class="site-title"> <a href="/">iCodeX's blog</a></h1><p class="site-subtitle fst-italic mb-0">Code. Learn. Write. Repeat</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <a href="https://github.com/icodex-s24" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://twitter.com/icodex-s24" aria-label="twitter" target="_blank" rel="noopener noreferrer" > <i class="fa-brands fa-x-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['j.doit926','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Estimated cost associated with memory and GPU devices while considering the RTX 4090's pricing and capabilities.</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>Estimated cost associated with memory and GPU devices while considering the RTX 4090's pricing and capabilities.</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1725696024" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Sep 7, 2024 </time> </span><div class="d-flex justify-content-between"> <span> By <em> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="973 words" > <em>5 min</em> read</span></div></div></div></header><div class="content"><p>Building a large language model (LLM) with a focus on using lower-cost GPUs, such as the NVIDIA RTX 4090, involves significant computational resources. Below is a detailed breakdown of the estimated costs associated with memory and GPU devices while considering the RTX 4090’s pricing and capabilities.</p><h3 id="1-understanding-model-parameters-and-memory-requirements"><span class="me-2">1. Understanding Model Parameters and Memory Requirements</span><a href="#1-understanding-model-parameters-and-memory-requirements" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="memory-requirements"><span class="me-2">Memory Requirements</span><a href="#memory-requirements" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>The memory required for training a model is primarily determined by the number of parameters and the precision used to store them. Here’s a general guideline:</p><ul><li><strong>Full Precision (float32)</strong>: Each parameter requires 4 bytes.<li><strong>Half Precision (float16)</strong>: Each parameter requires 2 bytes.</ul><p>To calculate the total memory requirement for a model, you can use the formula:</p>\[\text{Memory (in GB)} = \frac{\text{Number of Parameters} \times \text{Bytes per Parameter}}{1,073,741,824}\]<p>For example, for a 1 billion parameter model in full precision: \(\text{Memory} = \frac{1,000,000,000 \times 4}{1,073,741,824} \approx 3.73 \text{ GB}\)</p><h3 id="2-gpu-options-nvidia-rtx-4090"><span class="me-2">2. GPU Options: NVIDIA RTX 4090</span><a href="#2-gpu-options-nvidia-rtx-4090" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="nvidia-rtx-4090-specifications"><span class="me-2">NVIDIA RTX 4090 Specifications</span><a href="#nvidia-rtx-4090-specifications" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li><strong>Memory</strong>: 24 GB GDDR6X<li><strong>Price</strong>: Approximately <strong>$1,600 - $2,000</strong> (depending on the retailer and model)</ul><p>The RTX 4090 is a powerful GPU that can handle substantial workloads, making it suitable for training LLMs.</p><h3 id="example-calculation-for-model-training"><span class="me-2">Example Calculation for Model Training</span><a href="#example-calculation-for-model-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="1-billion-parameters"><span class="me-2">1 Billion Parameters</span><a href="#1-billion-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li><strong>Memory Requirement</strong>:<ul><li>Full Precision: \(1,000,000,000 \times 4 \text{ bytes} = 4 \text{ GB}\)</ul><li><strong>GPU Selection</strong>:<ul><li>A single <strong>NVIDIA RTX 4090</strong> (24 GB) can easily handle this model.<li><strong>Total GPU Cost</strong>: Approximately <strong>$1,600</strong>.</ul></ul><h4 id="7-billion-parameters"><span class="me-2">7 Billion Parameters</span><a href="#7-billion-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li><strong>Memory Requirement</strong>:<ul><li>Full Precision: \(7,000,000,000 \times 4 \text{ bytes} = 28 \text{ GB}\)</ul><li><strong>GPU Selection</strong>:<ul><li>A single <strong>NVIDIA RTX 4090</strong> can accommodate this model as well.<li><strong>Total GPU Cost</strong>: Approximately <strong>$1,600</strong>.</ul></ul><h4 id="175-billion-parameters"><span class="me-2">175 Billion Parameters</span><a href="#175-billion-parameters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li><strong>Memory Requirement</strong>:<ul><li>Full Precision: \(175,000,000,000 \times 4 \text{ bytes} = 700 \text{ GB}\)</ul><li><strong>GPU Selection</strong>:<ul><li>This model size exceeds the memory capacity of a single RTX 4090, requiring multiple GPUs.<li>You would need at least <strong>30 RTX 4090 GPUs</strong> to accommodate this model, costing approximately <strong>$48,000</strong>.</ul></ul><h3 id="3-estimating-training-time-and-costs"><span class="me-2">3. Estimating Training Time and Costs</span><a href="#3-estimating-training-time-and-costs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="training-time"><span class="me-2">Training Time</span><a href="#training-time" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Training time can vary widely based on several factors, including the architecture of the model, the efficiency of the training code, and the number of epochs. A rough estimate for training time can be derived from the following:</p><ul><li><strong>Batch Size</strong>: Larger batch sizes can speed up training but require more memory.<li><strong>Epochs</strong>: The total number of passes through the training dataset.</ul><p>For example, if you have:</p><ul><li>A dataset with 1 million samples<li>A batch size of 256<li>10 epochs</ul><p>The number of iterations would be: \(\text{Iterations} = \frac{1,000,000}{256} \times 10 \approx 39,062 \text{ iterations}\)</p><p>If each iteration takes approximately 0.1 seconds on an RTX 4090, the total training time would be: \(\text{Total Time} = 39,062 \times 0.1 \approx 3,906 \text{ seconds} \approx 1.08 \text{ hours}\)</p><h3 id="4-total-cost-estimation"><span class="me-2">4. Total Cost Estimation</span><a href="#4-total-cost-estimation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>To summarize the total costs associated with building an LLM using the NVIDIA RTX 4090:</p><ul><li><strong>1 Billion Parameters</strong>:<ul><li><strong>GPU Cost</strong>: Approximately <strong>$1,600</strong> for 1 RTX 4090.<li><strong>Total Memory Cost</strong>: Minimal additional costs for memory since it fits on one GPU.</ul><li><strong>7 Billion Parameters</strong>:<ul><li><strong>GPU Cost</strong>: Approximately <strong>$1,600</strong> for 1 RTX 4090.<li><strong>Total Memory Cost</strong>: Still manageable within the budget.</ul><li><strong>175 Billion Parameters</strong>:<ul><li><strong>GPU Cost</strong>: Approximately <strong>$48,000</strong> for 30 RTX 4090 GPUs.<li><strong>Total Memory Cost</strong>: Additional costs for high-capacity storage and memory may apply, but the primary cost is the GPUs.</ul></ul><h3 id="gpu-prices"><span class="me-2">GPU Prices</span><a href="#gpu-prices" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Here is a table with additional GPU devices like the RTX 4080 and A100:</p><div class="table-wrapper"><table><thead><tr><th>GPU<th>Memory<th>Memory Type<th>Memory Bus Width<th>Memory Bandwidth<th>CUDA Cores<th>Tensor Cores<th>RT Cores<th>Base Clock<th>Boost Clock<th>TDP<th>Price<tbody><tr><td>RTX 4090<td>24 GB<td>GDDR6X<td>384-bit<td>1,008 GB/s<td>16,384<td>512<td>128<td>2.23 GHz<td>2.52 GHz<td>450W<td>$1,599<tr><td>RTX 4080<td>16 GB<td>GDDR6X<td>256-bit<td>716 GB/s<td>9,728<td>304<td>76<td>2.21 GHz<td>2.51 GHz<td>320W<td>$1,199<tr><td>RTX 4070 Ti<td>12 GB<td>GDDR6X<td>192-bit<td>504 GB/s<td>7,680<td>240<td>60<td>2.31 GHz<td>2.61 GHz<td>285W<td>$799<tr><td>RTX 4070<td>12 GB<td>GDDR6<td>192-bit<td>504 GB/s<td>5,888<td>184<td>46<td>1.92 GHz<td>2.46 GHz<td>200W<td>$599<tr><td>RTX 4060 Ti<td>8 GB<td>GDDR6<td>128-bit<td>288 GB/s<td>4,352<td>136<td>34<td>1.87 GHz<td>2.37 GHz<td>200W<td>$399<tr><td>RTX 4060<td>8 GB<td>GDDR6<td>128-bit<td>288 GB/s<td>3,584<td>112<td>28<td>1.82 GHz<td>2.42 GHz<td>170W<td>$299<tr><td>RX 7900 XTX<td>24 GB<td>GDDR6<td>384-bit<td>960 GB/s<td>6,144<td>-<td>96<td>1.86 GHz<td>2.3 GHz<td>355W<td>$999<tr><td>RX 7900 XT<td>20 GB<td>GDDR6<td>320-bit<td>800 GB/s<td>5,376<td>-<td>84<td>1.86 GHz<td>2.25 GHz<td>300W<td>$899<tr><td>RX 7800 XT<td>16 GB<td>GDDR6<td>256-bit<td>560 GB/s<td>4,096<td>-<td>64<td>1.81 GHz<td>2.2 GHz<td>255W<td>$599<tr><td>A100<td>40 GB<td>HBM2<td>5120-bit<td>1.6 TB/s<td>6,912<td>432<td>-<td>1.41 GHz<td>1.71 GHz<td>400W<td>$10,000</table></div><p>This table includes the latest NVIDIA RTX 40-series and AMD RX 7000-series GPUs, as well as the NVIDIA A100 for comparison. Key specifications like memory size, type, bus width, bandwidth, CUDA/Tensor/RT cores, clock speeds, TDP, and pricing are provided for each model.</p><p>The RTX 4090 leads with its impressive 24 GB of GDDR6X memory and 1 TB/s of bandwidth, along with the highest core counts. The RTX 4080 and 4070 Ti offer great performance at lower prices. AMD’s RX 7900 XTX and XT compete well with the RTX 4080 and 4070 Ti respectively.</p><p>The NVIDIA A100 is included as a high-end data center GPU with its massive 40 GB HBM2 memory and 1.6 TB/s bandwidth, but at a much higher price point of $10,000.</p><p>This table allows for easy comparison of the key specifications and pricing across the latest desktop and data center GPUs from NVIDIA and AMD. The information is sourced from official product pages and reviews.</p><h3 id="conclusion"><span class="me-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Building an LLM from scratch using the NVIDIA RTX 4090 is feasible for smaller models, such as those with 1 billion or 7 billion parameters, with a total cost of approximately <strong>$1,600</strong>. However, for larger models (e.g., 175 billion parameters), the costs escalate significantly, requiring a substantial investment in multiple high-performance GPUs. Understanding these requirements will help you plan the computational resources needed for your LLM project effectively.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/ai/">AI</a>, <a href="/categories/llm/">LLM</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/build/" class="post-tag no-text-decoration" >build</a> <a href="/tags/llm/" class="post-tag no-text-decoration" >llm</a> <a href="/tags/budget/" class="post-tag no-text-decoration" >budget</a> <a href="/tags/estimation/" class="post-tag no-text-decoration" >estimation</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Estimated%20cost%20associated%20with%20memory%20and%20GPU%20devices%20while%20considering%20the%20RTX%204090's%20pricing%20and%20capabilities.%20-%20iCodeX's%20blog&url=%2Fposts%2Fbudget-own-llm-build%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Estimated%20cost%20associated%20with%20memory%20and%20GPU%20devices%20while%20considering%20the%20RTX%204090's%20pricing%20and%20capabilities.%20-%20iCodeX's%20blog&u=%2Fposts%2Fbudget-own-llm-build%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=%2Fposts%2Fbudget-own-llm-build%2F&text=Estimated%20cost%20associated%20with%20memory%20and%20GPU%20devices%20while%20considering%20the%20RTX%204090's%20pricing%20and%20capabilities.%20-%20iCodeX's%20blog" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/conditioning-habits/">Conditioning Habits - The Key to Lasting Change</a><li class="text-truncate lh-lg"> <a href="/posts/cover-6mn-study-in-3days/">Cramming Effectively - How to Cover 6 Months of Study in 72 Hours</a><li class="text-truncate lh-lg"> <a href="/posts/comparison-human-brain-supercomputer/">Human Brain vs. Supercomputer - A Hardware Perspective</a><li class="text-truncate lh-lg"> <a href="/posts/power-detachment/">The Power of Detachment - A Key to Better Decision-Making and Leadership</a><li class="text-truncate lh-lg"> <a href="/posts/how-use-docker-windows-offline/">Building a Docker Environment Completely Offline on Windows 10</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/basics/">basics</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/swiftui/">swiftui</a> <a class="post-tag btn btn-outline-primary" href="/tags/architecture/">architecture</a> <a class="post-tag btn btn-outline-primary" href="/tags/learning/">learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/habits/">habits</a> <a class="post-tag btn btn-outline-primary" href="/tags/strategy/">strategy</a> <a class="post-tag btn btn-outline-primary" href="/tags/swift5-0/">swift5.0</a> <a class="post-tag btn btn-outline-primary" href="/tags/swift5-1/">swift5.1</a></div></section></div><section id="toc-wrapper" class="d-none ps-0 pe-4"><h2 class="panel-heading ps-3 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/3-ways-build-own-llms/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1725707425" data-df="ll" > Sep 7, 2024 </time><h4 class="pt-0 my-2">3 Ways to Build your Own LLMs</h4><div class="text-muted"><p>(00:00) one of the most common asks I get from clients is how do I build a custom AI chatbot well a few months ago this was something you needed to hire a consultant for today that’s not necessaril...</p></div></div></a></article><article class="col"> <a href="/posts/build-llm-from-scratch/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1725705886" data-df="ll" > Sep 7, 2024 </time><h4 class="pt-0 my-2">Build an LLM from scratch</h4><div class="text-muted"><p>(00:00) hey everyone I’m sha and this is the sixth video in the larger series on how to use large language models in practice in this video I’m going to review key aspects and considerations for bu...</p></div></div></a></article><article class="col"> <a href="/posts/llm-comparison-2024/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1725445300" data-df="ll" > Sep 4, 2024 </time><h4 class="pt-0 my-2">Small LLM Comparison in 2024</h4><div class="text-muted"><p>Timeline of major LLM developments from 2019 to 2024, here are the top 3 Large Language Models (LLMs) in various domains, their key specifications, and performance suitability: Do...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/prompt-engineering/" class="btn btn-outline-primary" aria-label="Older" ><p>Prompt Engineering</p></a> <a href="/posts/build-llm-from-scratch/" class="btn btn-outline-primary" aria-label="Newer" ><p>Build an LLM from scratch</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://twitter.com/icodex-s24">icodex-s24</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.1.0" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/basics/">basics</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/swiftui/">swiftui</a> <a class="post-tag btn btn-outline-primary" href="/tags/architecture/">architecture</a> <a class="post-tag btn btn-outline-primary" href="/tags/learning/">learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/habits/">habits</a> <a class="post-tag btn btn-outline-primary" href="/tags/strategy/">strategy</a> <a class="post-tag btn btn-outline-primary" href="/tags/swift5-0/">swift5.0</a> <a class="post-tag btn btn-outline-primary" href="/tags/swift5-1/">swift5.1</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script src="/assets/lib/simple-jekyll-search/simple-jekyll-search.min.js"></script> <script src="/assets/lib/loading-attribute-polyfill/loading-attribute-polyfill.umd.min.js"></script> <script src="/assets/lib/glightbox/glightbox.min.js"></script> <script src="/assets/lib/clipboard/clipboard.min.js"></script> <script src="/assets/lib/dayjs/dayjs.min.js"></script> <script src="/assets/lib/dayjs/locale/en.js"></script> <script src="/assets/lib/dayjs/plugin/relativeTime.js"></script> <script src="/assets/lib/dayjs/plugin/localizedFormat.js"></script> <script src="/assets/lib/tocbot/tocbot.min.js"></script> <script src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js"></script> <script>SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
